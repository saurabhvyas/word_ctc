{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conditional GAN to create mnist image samples from latent space ( noise ) and y ( class label , in this case digit label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_dim = mnist.train.labels.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Params\n",
    "num_steps = 70000\n",
    "batch_size = 128\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# Network Params\n",
    "image_dim = 784 # 28*28 pixels\n",
    "gen_hidden_dim = 256\n",
    "disc_hidden_dim = 256\n",
    "noise_dim = 100 # Noise data points\n",
    "\n",
    "# A custom initialization (see Xavier Glorot init)\n",
    "def glorot_init(shape):\n",
    "    return tf.random_normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'gen_hidden1': tf.Variable(glorot_init([noise_dim + y_dim, gen_hidden_dim])),\n",
    "    'gen_out': tf.Variable(glorot_init([gen_hidden_dim, image_dim])),\n",
    "    'disc_hidden1': tf.Variable(glorot_init([image_dim + y_dim, disc_hidden_dim])),\n",
    "    'disc_out': tf.Variable(glorot_init([disc_hidden_dim, 1])),\n",
    "}\n",
    "biases = {\n",
    "    'gen_hidden1': tf.Variable(tf.zeros([gen_hidden_dim])),\n",
    "    'gen_out': tf.Variable(tf.zeros([image_dim])),\n",
    "    'disc_hidden1': tf.Variable(tf.zeros([disc_hidden_dim])),\n",
    "    'disc_out': tf.Variable(tf.zeros([1])),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator\n",
    "def generator(x,y):\n",
    "    \n",
    "    x=tf.concat(axis=1, values=[x, y])\n",
    "    hidden_layer = tf.matmul(x, weights['gen_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['gen_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['gen_out'])\n",
    "    out_layer = tf.add(out_layer, biases['gen_out'])\n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "# Discriminator\n",
    "def discriminator(x,y):\n",
    "    \n",
    "    x=tf.concat(axis=1, values=[x, y])\n",
    "    hidden_layer = tf.matmul(x, weights['disc_hidden1'])\n",
    "    hidden_layer = tf.add(hidden_layer, biases['disc_hidden1'])\n",
    "    hidden_layer = tf.nn.relu(hidden_layer)\n",
    "    out_layer = tf.matmul(hidden_layer, weights['disc_out'])\n",
    "    out_layer = tf.add(out_layer, biases['disc_out'])\n",
    "    out_layer = tf.nn.sigmoid(out_layer)\n",
    "    return out_layer\n",
    "\n",
    "# Build Networks\n",
    "# Network Inputs\n",
    "gen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name='input_noise')\n",
    "disc_input = tf.placeholder(tf.float32, shape=[None, image_dim], name='disc_input')\n",
    "y_generator = tf.placeholder(tf.float32, shape=[None, y_dim])  # this is conditional class label input placeholder for generator\n",
    "y_discriminator = tf.placeholder(tf.float32, shape=[None, y_dim])  # this is conditional class label input placeholder for discriminator\n",
    "\n",
    "# Build Generator Network\n",
    "gen_sample = generator(gen_input,y_generator)\n",
    "\n",
    "# Build 2 Discriminator Networks (one from noise input, one from generated samples)\n",
    "disc_real = discriminator(disc_input,y_discriminator)\n",
    "disc_fake = discriminator(gen_sample, y_discriminator)\n",
    "\n",
    "# Build Loss\n",
    "gen_loss = -tf.reduce_mean(tf.log(disc_fake))\n",
    "disc_loss = -tf.reduce_mean(tf.log(disc_real) + tf.log(1. - disc_fake))\n",
    "\n",
    "# Build Optimizers\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Training Variables for each optimizer\n",
    "# By default in TensorFlow, all variables are updated by each optimizer, so we\n",
    "# need to precise for each one of them the specific variables to update.\n",
    "# Generator Network Variables\n",
    "gen_vars = [weights['gen_hidden1'], weights['gen_out'],\n",
    "            biases['gen_hidden1'], biases['gen_out']]\n",
    "# Discriminator Network Variables\n",
    "disc_vars = [weights['disc_hidden1'], weights['disc_out'],\n",
    "            biases['disc_hidden1'], biases['disc_out']]\n",
    "\n",
    "# Create training operations\n",
    "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
    "train_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Generator Loss: 0.640419, Discriminator Loss: 1.380829\n",
      "Step 2000: Generator Loss: 5.503186, Discriminator Loss: 0.016003\n",
      "Step 4000: Generator Loss: 4.397339, Discriminator Loss: 0.046400\n",
      "Step 6000: Generator Loss: 4.460683, Discriminator Loss: 0.104719\n",
      "Step 8000: Generator Loss: 4.392978, Discriminator Loss: 0.136222\n",
      "Step 10000: Generator Loss: 4.280320, Discriminator Loss: 0.179940\n",
      "Step 12000: Generator Loss: 4.460572, Discriminator Loss: 0.121632\n",
      "Step 14000: Generator Loss: 5.093113, Discriminator Loss: 0.197632\n",
      "Step 16000: Generator Loss: 5.534423, Discriminator Loss: 0.171643\n",
      "Step 18000: Generator Loss: 7.353442, Discriminator Loss: 0.021188\n",
      "Step 20000: Generator Loss: 6.028141, Discriminator Loss: 0.064577\n",
      "Step 22000: Generator Loss: 5.552356, Discriminator Loss: 0.161504\n",
      "Step 24000: Generator Loss: 6.272092, Discriminator Loss: 0.118927\n",
      "Step 26000: Generator Loss: 7.034872, Discriminator Loss: 0.158477\n",
      "Step 28000: Generator Loss: 6.775108, Discriminator Loss: 0.103515\n",
      "Step 30000: Generator Loss: 7.354128, Discriminator Loss: 0.076966\n",
      "Step 32000: Generator Loss: 6.572168, Discriminator Loss: 0.119620\n",
      "Step 34000: Generator Loss: 6.527016, Discriminator Loss: 0.107253\n",
      "Step 36000: Generator Loss: 7.006756, Discriminator Loss: 0.089476\n",
      "Step 38000: Generator Loss: 6.570609, Discriminator Loss: 0.187157\n",
      "Step 40000: Generator Loss: 6.350962, Discriminator Loss: 0.119635\n",
      "Step 42000: Generator Loss: 7.647642, Discriminator Loss: 0.228882\n",
      "Step 44000: Generator Loss: 6.809158, Discriminator Loss: 0.275855\n",
      "Step 46000: Generator Loss: 6.126747, Discriminator Loss: 0.154561\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-da16e6d73377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mdisc_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_sample\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_discriminator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_mnist\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n\u001b[0;32m---> 23\u001b[0;31m                             feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Step %i: Generator Loss: %f, Discriminator Loss: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start Training\n",
    "# Start a new TF session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps+1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, y_mnist = mnist.train.next_batch(batch_size)\n",
    "    \n",
    "    y_sample = np.zeros(shape=[batch_size, y_dim])\n",
    "    y_sample[:, 7] = 1\n",
    "    \n",
    "    # Generate noise to feed to the generator\n",
    "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
    "\n",
    "    # Train\n",
    "    feed_dict = {disc_input: batch_x, gen_input: z , y_generator:y_sample , y_discriminator:y_mnist}\n",
    "    _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n",
    "                            feed_dict=feed_dict)\n",
    "    if i % 2000 == 0 or i == 1:\n",
    "        print('Step %i: Generator Loss: %f, Discriminator Loss: %f' % (i, gl, dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAFpCAYAAACBNaNRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f60afee1ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing\n",
    "# Generate images from noise, using the generator network.\n",
    "n = 6\n",
    "canvas = np.empty((28 * n, 28 * n))\n",
    "\n",
    "# Noise input.\n",
    "z = np.random.uniform(-1., 1., size=[n, noise_dim])\n",
    "    \n",
    "    \n",
    "# generate class label y for each sample\n",
    "y_sample = np.zeros(shape=[6, y_dim])\n",
    "y_sample[:, 5] = 1\n",
    "    \n",
    "    \n",
    "# Generate image from noise.\n",
    "g = sess.run(gen_sample, feed_dict={gen_input: z , y_generator:y_sample})\n",
    "# Reverse colours for better display\n",
    "g = -1 * (g - 1)\n",
    "for j in range(n):\n",
    "    # Draw the generated digits\n",
    "    canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
    "\n",
    "plt.figure(figsize=(n, n))\n",
    "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_orange",
   "language": "python",
   "name": "tf_orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
