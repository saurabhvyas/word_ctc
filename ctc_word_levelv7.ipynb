{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  word level CTC\n",
    "# tensorflow version 1.3\n",
    "# personal note, CTC Tensorflow documentation is not at all clear and intuitive , so if confused refer to any example\n",
    "# note for decoder, the input has to be in this format 3-D float Tensor sized [max_time x batch_size x num_classes]\n",
    "# it doesn't support time major option\n",
    "\n",
    "# from v4 onwards trying to integrate dataset api\n",
    "\n",
    "# to do : padding numpy arrays dynamically  , graphical loss function , testing on realdataset , expand word dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from tensorflow.contrib.data import Dataset, Iterator\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audio_to_mfcc(fileurl):\n",
    "    rate, sig = wav.read(fileurl)\n",
    "    mfcc_feat = mfcc(sig,rate)\n",
    "#d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "#fbank_feat = logfbank(sig,rate)\n",
    "\n",
    "    return mfcc_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = audio_to_mfcc('/home/saurabh/Documents/tf_orange/tf_orange/data/test.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_csv(line):\n",
    "       parsed_line = tf.decode_csv(line, [[\"\"],[\"\"]])\n",
    "       \n",
    "    \n",
    "       \n",
    "       \n",
    "\n",
    "       return parsed_line[0] , parsed_line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we also need a fixed vocabulary \n",
    "import re\n",
    "\n",
    "word_dictionary = {'hello':0 , 'world':1 , ' ':2}\n",
    "\n",
    "\n",
    "def word_to_index(sentence):\n",
    "   \n",
    "    words = sentence.split(' ')\n",
    "    index_list=[]\n",
    "    for word in words:\n",
    "        if word in word_dictionary:\n",
    "           # print(word)\n",
    "            index_list.insert(len(index_list) , word_dictionary[word])\n",
    "            index_list.insert(len(index_list) , word_dictionary[' '])\n",
    "    index_list.pop()        \n",
    "    return index_list\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _read_py_function(audio, label):\n",
    "    audio =audio_to_mfcc(audio)\n",
    "   \n",
    "    return audio ,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.contrib.data.TextLineDataset(\"/home/saurabh/Documents/tf_orange/tf_orange/data/data.csv\")\n",
    "dataset=dataset.map(decode_csv)\n",
    "\n",
    "\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda audio, label: tuple(tf.py_func(\n",
    "        _read_py_function, [audio, label], [tf.double, label.dtype])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset=dataset.batch(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "training_init_op = iterator.make_initializer(dataset)\n",
    "\n",
    "item = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function is required for CTC Loss\n",
    "# for it's input , first convert transcrition / ground truth to number representation \n",
    "\n",
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    \"\"\"Create a sparse representention of x.\n",
    "    Args:\n",
    "        sequences: a list of lists of type dtype where each element is a sequence\n",
    "    Returns:\n",
    "        A tuple with (indices, values, shape)\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n]*len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1]+1], dtype=np.int64)\n",
    "\n",
    "    return indices, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 20\n",
    "batch_size = 2\n",
    "display_step = 200\n",
    "num_features = 13\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 28 #  data input (img shape: 28*28)\n",
    "timesteps = 299 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 4 # hello , world , blank and space \n",
    "\n",
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([batch_size, 2 * num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell_fw = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "    lstm_cell_bw = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    \n",
    "    # Get lstm cell output\n",
    "    outputs, _, _ = rnn.static_bidirectional_rnn(lstm_cell_fw, lstm_cell_bw, x,\n",
    "    dtype=tf.float32)\n",
    "    \n",
    "    #convert output shape (timesteps * batch * classes ) to (batch*timesteps*classes)\n",
    "    outputs=tf.transpose( outputs , [1, 0, 2])\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    res =  tf.matmul(outputs, weights['out']) + biases['out']\n",
    "    \n",
    "    return res\n",
    "   # return tf.nn.softmax(tf.matmul(outputs, weights['out']) + biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#prediction = tf.nn.softmax(logits)\n",
    "inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "targets = tf.sparse_placeholder(tf.int32)\n",
    "seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "\n",
    "# padding code start\n",
    "\n",
    "''' \n",
    "max_length = tf.reduce_max(seq_len)\n",
    "\n",
    "\n",
    "def f1(): return print (\"needs padding\")\n",
    "\n",
    "r = tf.cond(tf.less( tf.shape(seq_len[0])[0] , max_length  ), f1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# padding code end\n",
    "\n",
    "'''\n",
    "\n",
    "logits = RNN(inputs, weights, biases)\n",
    "\n",
    "loss =  tf.nn.ctc_loss ( targets, logits , seq_len , time_major = False)\n",
    "cost = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                           0.9).minimize(cost)\n",
    "\n",
    "\n",
    "# Option 2: tf.contrib.ctc.ctc_beam_search_decoder\n",
    "    # (it's slower but you'll get better results)\n",
    "decoder_input = tf.transpose(logits, [1, 0, 2])\n",
    "\n",
    "decoded, log_prob = tf.nn.ctc_greedy_decoder(decoder_input, seq_len)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need this for decoding word give its index key value \n",
    "\n",
    "def keys_of_value(dct, value):\n",
    "    for k in dct:\n",
    "        if isinstance(dct[k], list):\n",
    "            if value in dct[k]:\n",
    "                return k\n",
    "        else:\n",
    "            if value == dct[k]:\n",
    "                return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 299, 13)\n",
      "<class 'numpy.ndarray'>\n",
      "[0, 2, 1, 2, 0, 2, 1]\n",
      "[1, 2, 1, 2, 1]\n",
      "(299, 13)\n",
      "needs padding\n",
      "difference : 1\n",
      "(299, 13)\n",
      "needs padding\n",
      "difference : 1\n",
      "max_len : 300\n",
      "[299, 299]\n",
      "406.555\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      "End of training dataset.\n",
      " \n",
      " world \n",
      "813.110473633\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    sess.run(training_init_op)\n",
    "    \n",
    "\n",
    "\n",
    "    #print(train_seq_len)\n",
    "    \n",
    "    for curr_epoch in range(training_steps):\n",
    "        train_cost = train_ler = 0\n",
    "        start = time.time()\n",
    "        \n",
    "       \n",
    "\n",
    "        while True: \n",
    "            try:\n",
    "                \n",
    "                max_len=300\n",
    "                \n",
    "                \n",
    "                temp_np_inputs = np.zeros((batch_size , max_len , 13 ))\n",
    "            \n",
    "           \n",
    "                elem = sess.run(item)\n",
    "                print(elem[0].shape)\n",
    "                print(type(elem[0]))\n",
    "                \n",
    "                for label in elem[1]:\n",
    "                    print (word_to_index(label.decode(\"utf-8\")) )\n",
    "                \n",
    "                batch_inputs=elem[0]\n",
    "                \n",
    "                batch_lengths=[]\n",
    "                \n",
    "            \n",
    "                for index,test_item in enumerate(batch_inputs):\n",
    "                \n",
    "                    print (test_item.shape)\n",
    "                    max_len=max(max_len, test_item.shape[0])\n",
    "                    batch_lengths.insert(index, test_item.shape[0])\n",
    "                    \n",
    "                    if test_item.shape[0] < max_len:\n",
    "                        print(\"needs padding\")\n",
    "                        difference = max_len - test_item.shape[0]\n",
    "                        print(\"difference : \" + str(difference))\n",
    "                        temp_np_inputs[index] = np.pad(test_item,((0,difference),(0,0)), mode=\"constant\")\n",
    "        \n",
    "                print('max_len : ' + str(max_len) )\n",
    "            \n",
    "                batch_list = []\n",
    "                \n",
    "                print(batch_lengths)\n",
    "                \n",
    "            \n",
    "                for index,j in enumerate(elem[1]):\n",
    "                    batch_list.insert(index, word_to_index(j.decode(\"utf-8\")))\n",
    "                    \n",
    "                \n",
    "                batch_targets = sparse_tuple_from(batch_list)\n",
    "                \n",
    "                \n",
    "                \n",
    "             \n",
    "                \n",
    "                \n",
    "            \n",
    "                feed = {inputs: batch_inputs,\n",
    "                        targets: batch_targets,\n",
    "                        seq_len: batch_lengths}\n",
    "\t    \n",
    "\n",
    "                batch_cost, _ = sess.run([cost, optimizer], feed)\n",
    "                print(batch_cost)\n",
    "                \n",
    "               \n",
    "                \n",
    "            except tf.errors.OutOfRangeError:\n",
    "                print(\"End of training dataset.\")\n",
    "                break\n",
    "    \n",
    "    # Decoding\n",
    "    d = sess.run(decoded[0], feed_dict=feed)\n",
    "   \n",
    "    dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=sess)\n",
    "    \n",
    "    for i, seq in enumerate(dense_decoded):\n",
    "\n",
    "        seq = [s for s in seq if s != -1]\n",
    "       \n",
    "        str_decoded = ''.join([keys_of_value(word_dictionary, x) for x in seq ])\n",
    "        print(str_decoded)\n",
    "    \n",
    " \n",
    "    \n",
    "    train_cost += batch_cost*batch_size\n",
    "    print(train_cost)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_orange",
   "language": "python",
   "name": "tf_orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
