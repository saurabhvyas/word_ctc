{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  word level CTC  tensorflow version 1.3\n",
    "\n",
    "# this module requires the following :\n",
    "\n",
    "#  a dataset csv file ( have a look at dataset csv generator)\n",
    "#  a dictionary.txt file ( have a look at dictionary folder)\n",
    "\n",
    "\n",
    "\n",
    "# to do :   \n",
    "#  , testing on realdataset , get rid of fixed batch size , instead use variable batch size  \n",
    "\n",
    "\n",
    "# perform following tests :\n",
    "\n",
    "# 1. variable batch sizes test\n",
    "# 2. GPU test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# please change the following according to your system\n",
    "# hyperparameters in this notebook\n",
    "\n",
    "# change paths in this notebook to that corresponding to your system\n",
    "# please note number of audio examples in dataset must be even \n",
    "\n",
    "# peace.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from tensorflow.contrib.data import Dataset, Iterator\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audio_to_mfcc(fileurl):\n",
    "    rate, sig = wav.read(fileurl)\n",
    "    mfcc_feat = mfcc(sig,rate)\n",
    "#d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "#fbank_feat = logfbank(sig,rate)\n",
    "\n",
    "    return mfcc_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = audio_to_mfcc('data/hardik_500/5.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_csv(line):\n",
    "       parsed_line = tf.decode_csv(line, [[\"\"],[\"\"]])\n",
    "       \n",
    "    \n",
    "       \n",
    "       \n",
    "\n",
    "       return parsed_line[0] , parsed_line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we also need a fixed vocabulary \n",
    "import re\n",
    "\n",
    "word_dictionary = {}\n",
    "\n",
    "with open(\"words/hardik_words.txt\") as file:\n",
    "    for i , line in enumerate(file):\n",
    "        \n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        word_dictionary[line] = i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1303\n"
     ]
    }
   ],
   "source": [
    "print(len(word_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def word_to_index(sentence):\n",
    "   \n",
    "    words = sentence.split(' ')\n",
    "    index_list=[]\n",
    "    for word in words:\n",
    "       \n",
    "        if word in word_dictionary:\n",
    "           # print(word)\n",
    "            index_list.insert(len(index_list) , word_dictionary[word])\n",
    "            index_list.insert(len(index_list) , word_dictionary[' '])\n",
    "    index_list.pop()        \n",
    "    return index_list\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-3eb6f43c5fd7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-3eb6f43c5fd7>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    word_to_index('I don't wanna say')\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "word_to_index('I don't wanna say')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function, that pads audio so that audio frames = max frames\n",
    "\n",
    "def pad(input):\n",
    "   # print(input.shape[0])\n",
    "     if input.shape[0] < timesteps:\n",
    "        \n",
    "        diff = timesteps - input.shape[0]\n",
    "        \n",
    "        # pad and return input\n",
    "        return np.pad(input,((0,diff),(0,0)), mode=\"constant\")\n",
    "    \n",
    "     elif input.shape[0] > timesteps:\n",
    "        \n",
    "        return input[:timesteps,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _read_py_function(audio, label):\n",
    "    audio = audio_to_mfcc(audio)\n",
    "    \n",
    "    if audio.shape[0] < timesteps:\n",
    "        original_length=audio.shape[0]\n",
    "       # print(original_length)\n",
    "    \n",
    "    elif audio.shape[0] >= timesteps:\n",
    "        original_length=timesteps\n",
    "        \n",
    "    \n",
    "    audio=pad(audio)\n",
    "   \n",
    "    return audio ,label, original_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-dede7f851504>:1: TextLineDataset.__init__ (from tensorflow.contrib.data.python.ops.readers) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.TextLineDataset`.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.contrib.data.TextLineDataset(\"hardik2.csv\")\n",
    "dataset=dataset.map(decode_csv)\n",
    "\n",
    "\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda audio, label: tuple(tf.py_func(\n",
    "        _read_py_function, [audio, label], [tf.double, label.dtype, tf.int64])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset=dataset.batch(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "item = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function is required for CTC Loss\n",
    "# for it's input , first convert transcrition / ground truth to number representation \n",
    "\n",
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    \"\"\"Create a sparse representention of x.\n",
    "    Args:\n",
    "        sequences: a list of lists of type dtype where each element is a sequence\n",
    "    Returns:\n",
    "        A tuple with (indices, values, shape)\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n]*len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1]+1], dtype=np.int64)\n",
    "\n",
    "    return indices, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.01\n",
    "training_steps = 100\n",
    "#batch_size = 2\n",
    "display_step = 200\n",
    "num_features = 13\n",
    "logs_path = '/home/saurabh/Documents/tf_orange/tf_orange/hardik/logs'\n",
    "model_path = '/home/saurabh/Documents/tf_orange/tf_orange/models/hardik/model_500.ckpt'\n",
    "\n",
    "# Network Parameters\n",
    "\n",
    "timesteps = 449 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = len(word_dictionary) + 1 # words.txt , all words plus space word  ( 10001) + CTC symbol (1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction = tf.nn.softmax(logits)\n",
    "inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "targets = tf.sparse_placeholder(tf.int32)\n",
    "seq_len = tf.placeholder(tf.int32, [None])\n",
    "batch_size = 4\n",
    "\n",
    "#batch_size = tf.placeholder ( tf.int32 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[b'Flexible battery inspired by human spine'\n",
      " b'Amateur radio astronomer discovers long-lost satellite'\n",
      " b'community members visit India' b'Moderate Blood Sugar Levels']\n",
      "1\n",
      "[b'health benefits of pear consumption' b'Fell Asleep With Headache'\n",
      " b'Woke Up With A British Accent' b\"Don't want to diet?\"]\n",
      "2\n",
      "[b'lose weight by following this simple trick'\n",
      " b'Diarrhoea outbreak in Kolkata'\n",
      " b\"A concise look at Darwin's Theory of Evolution and its criticism\"\n",
      " b'tax you have to pay']\n",
      "3\n",
      "[b'Image Makeover Under ' b'100 Per Cent Placement'\n",
      " b'Midcap continues to outperform' b\"boost India's energy security\"]\n",
      "4\n",
      "[b\"India's ultra rich spend?\" b'restructured accounts will maintain'\n",
      " b'board accepts resignation' b'Riding on regulatory win']\n",
      "5\n",
      "[b'Scariest Flight Of My Life' b'bet a million on you'\n",
      " b'no way around this' b\"only way now it's through\"]\n",
      "6\n",
      "[b'gonna cry myself to sleep' b'kept you to winter'\n",
      " b\"you won't be needing me\" b'not in front of me']\n",
      "7\n",
      "[b'catch your tears' b'leave me this way' b'A puddle of water'\n",
      " b'Asus Zenfone 5']\n",
      "8\n",
      "[b'Kill the chattering' b'Keep the voices from screaming' b'Pull me out'\n",
      " b'the pain is great']\n",
      "9\n",
      "[b'here you are' b'running out of breath' b'i got stamina'\n",
      " b'i close my eyes']\n",
      "10\n",
      "[b'another mountain to climb' b\"Don't give up\"\n",
      " b\"don't wanna fight anymore\" b'Rough seas will be calm']\n",
      "11\n",
      "[b'we weather the storm' b'dogs playing dead' b'not worth playing chicken'\n",
      " b'discarding you like broken glass']\n",
      "12\n",
      "[b'no winners when the die' b\"it's the final dance\" b\"So don't give up\"\n",
      " b\"just young lovers' romance\"]\n",
      "13\n",
      "[b'Keep you to Winter' b'Alarming increase in tobacco related cancer'\n",
      " b\"E-cigarettes 'should be on prescription'\" b'Disturbing trend']\n",
      "14\n",
      "[b'Two cosmonauts break record for longest Russian spacewalk'\n",
      " b'Cholera alert in State' b'announcements may help you save tax'\n",
      " b'Post Budget blues continue']\n",
      "15\n",
      "[b'Electric vehicle scene still sketchy' b'Tata Motors Q3 profit surges'\n",
      " b'French delegation' b'CBI books billionaire']\n",
      "16\n",
      "[b'States not in favour of petrol' b'M&M introduces mHAWK engine'\n",
      " b'Boeing in talks with Indian Navy'\n",
      " b'Dance of galaxies challenges current thinking on cosmology']\n",
      "17\n",
      "[b'diesel at all-time high in Delhi' b'These Two Firms Are In Race'\n",
      " b'Niti Aayog health index' b'Trade setup for Tuesday']\n",
      "18\n",
      "[b'million stake sale in Tata Technologies'\n",
      " b'Bitcoin newbies are getting crushed'\n",
      " b'Singtel to invest in Bharti Telecom'\n",
      " b'Khadi commission seeks compensation from Fabindia']\n",
      "19\n",
      "[b'surprise Korean court verdict'\n",
      " b\"a solution to a problem that doesn't exist\"\n",
      " b'Inner Ear Helps Cheetah Run Fast'\n",
      " b'US ban Bitcoin buying with credit cards']\n",
      "20\n",
      "[b'judges facing intimidation' b'Pakistan government to arrest him'\n",
      " b'Muslim youngsters to attack' b'49% of Iranians against compulsory veil']\n",
      "21\n",
      "[b'6 tortured arguments Republicans are making'\n",
      " b'Donald Trump over NHS comments' b'Oil tanker continues to be missing'\n",
      " b'Paris attacks suspect']\n",
      "22\n",
      "[b'Chinese shipping firm MD killed'\n",
      " b'Amateur radio astronomer discovers long-lost satellite'\n",
      " b'Indian-Americans hold rally outside White House'\n",
      " b'Chinese Incursions Into India Rose']\n",
      "23\n",
      "[b'This gene could prevent heart disease' b'still a problem in India'\n",
      " b\"Whales are at 'significant' risk from ocean microplastic\"\n",
      " b'falling victim to diabetes']\n",
      "24\n",
      "[b'Weird Sensation Was A Stray Eyelash'\n",
      " b'Money only buys happiness for a certain amount'\n",
      " b'people get aggressive after a drink or two'\n",
      " b'Scientists unearth hope for new antibiotics']\n",
      "25\n",
      "[b'Digital scanning technology' b'India opens free camp'\n",
      " b'Kill Cancer By Choking Off Its Life Blood'\n",
      " b'5 Worst Foods For Your Brain']\n",
      "26\n",
      "[b'Swimming in cold water'\n",
      " b\"World's smallest satellite-carrying rocket launched\"\n",
      " b'alternative to pain killers' b'locations where it will be visible']\n",
      "27\n",
      "[b'Will Astronomers Be Ready' b'Global sea level surging at faster rate'\n",
      " b'Elon Musk reacts moments before' b'budget focuses on Moon']\n",
      "28\n",
      "[b'NASA ends pioneering pollution sensor' b'purple total solar eclipse'\n",
      " b'launch its satellite internet prototypes'\n",
      " b'marine ecosystem hidden beneath']\n",
      "29\n",
      "[b'Twist in out-of-Africa theory' b'just sending AI messages'\n",
      " b'The crowds are back' b'Are we all alone in the Universe']\n",
      "30\n",
      "[b'Redmi Note 5 launch' b'emails will change the way people interact'\n",
      " b'Maximum Prepaid Plan' b'Nokia 8 Starts Receiving Android']\n",
      "31\n",
      "[b'gears up for India expansion' b'Mercedes Benz C Class Revealed'\n",
      " b'Samsung Galaxy S9 to Feature 3D Emoji'\n",
      " b\"Indian scientists develop world's thinnest material with novel technique\"]\n",
      "32\n",
      "[b\"Google's Reply App Spotted in Testing\"\n",
      " b'Facebook app now available for JioPhone' b'Benchmarked Ahead of Debut'\n",
      " b'cashback under Flipkart Apple sale']\n",
      "33\n",
      "[b'Spectra Fastest Package for its customers'\n",
      " b'Snapchat opens up Snap Map on web' b'Enters Final Year Field Tests'\n",
      " b'Google is good at building phones']\n",
      "34\n",
      "[b'First Look Video at Auto Expo'\n",
      " b'Oracle expands global startup ecosystem'\n",
      " b\"A fast moving 'Potentially Hazardous' asteroid will zoom past Earth\"\n",
      " b'smooth interface without any slowdown']\n",
      "35\n",
      "[b'family targeted in South Africa' b'spies issue a challenge'\n",
      " b'Trump attorney says he made' b'Strong political case for intervention ']\n",
      "36\n",
      "[b'police recommend corruption charges'\n",
      " b'global terrorist financing watchlist' b'Widespread Damage From Cyclone'\n",
      " b'without compromising your Christian faith']\n",
      "37\n",
      "[b'makes Americans more secure'\n",
      " b'Super Blue Blood Moon and Lunar Eclipse in 60 seconds'\n",
      " b'visit shows he considers' b'to discuss bilateral relations']\n",
      "38\n",
      "[b'India should use military agreement'\n",
      " b'proven Syria using chemical arms' b\"UN Security Council has 'failed'\"\n",
      " b'Russian officials dispute reports']\n",
      "39\n",
      "[b\"Afghanistan's policies different from Obama's?\"\n",
      " b'Oxfam rocked by corruption' b'Canada wants answers after Iran'\n",
      " b'Syria poses new dangers to US']\n",
      "40\n",
      "[b'Meditation has limited role in making you a better person'\n",
      " b'Domestic Abuse and the White House' b'body found in bed box'\n",
      " b'warns youth from celebrating']\n",
      "41\n",
      "[b'Man Wanted For Law Student' b'keep striving for special status'\n",
      " b'effective booth management' b'Odd even not a permanent solution']\n",
      "42\n",
      "[b'Northern Command chief' b'Campus placement at IIMs'\n",
      " b'Lawmaker Watches His Son Beat Up'\n",
      " b'A four-day meet on Astronomy begins at Hyderabad']\n",
      "43\n",
      "[b'uninterruptible dialogue between India Pakistan'\n",
      " b\"Rover to spend 14 days on moon's surface\" b'Who are your friends?'\n",
      " b'Spicejet to shift operations']\n",
      "44\n",
      "[b'but I keep falling down' b'nothing comes now' b'I know peace will come'\n",
      " b'wanted to need someone']\n",
      "45\n",
      "[b'wanted to play tough' b'do all just on my own'\n",
      " b\"Sometimes needed Superman's soul\" b'Help me out of this hell']\n",
      "46\n",
      "[b'lifts me up like helium'\n",
      " b'Redmi 5 could be launched in India on February 14'\n",
      " b\"When I've hit the ground\" b'float towards the sun']\n",
      "47\n",
      "[b'you fill me up' b'drift towards the ground' b\"lucky that you're around\"\n",
      " b'bring a bottle of rum']\n",
      "48\n",
      "[b'cream and whiskey bourbon' b'We got nothing to lose'\n",
      " b'bring a friend if you please' b'all the misfit and us']\n",
      "49\n",
      "[b\"TVS Motor launches India's first connected scooter\"\n",
      " b'get better than this' b'be our family' b'this is Christmas baby']\n",
      "50\n",
      "[b'Bring them all to their knees' b'Take a trip down'\n",
      " b\"It's the cutest thing\" b'so get dressed']\n",
      "51\n",
      "[b'colors of the rainbow' b\"It's so magical\" b'go there in your dreams'\n",
      " b'Apple raises iPhone prices in India']\n",
      "52\n",
      "[b'You with the lights' b'Red yellow pink green'\n",
      " b'Orange and purple and blue' b'Christmas is waiting for you']\n",
      "53\n",
      "[b'a friend this holiday' b'who loves to play' b'eat all the candy canes'\n",
      " b'down to meet us']\n",
      "54\n",
      "[b'We can dance' b'everything is possible'\n",
      " b'2018 iPhone Models to Exclusively Use Intel Modems'\n",
      " b'For the puppy in the window']\n",
      "55\n",
      "[b'I can see him' b'he sees a friend in me' b'Oh how much'\n",
      " b'waiting to come home']\n",
      "56\n",
      "[b'Found my best friend' b'At the old dog pound' b'Puppies are forever'\n",
      " b'old and slow']\n",
      "57\n",
      "[b'never let you go'\n",
      " b'Hyundai Elite i20 facelift India launch confirmed at Auto Expo'\n",
      " b\"you're my family\" b'oh my cute']\n",
      "58\n",
      "[b'Wait for the snow' b'I will read the last' b'that they wrote'\n",
      " b'by the open fire']\n",
      "59\n",
      "[b'you is a gift tonight' b'for all my life' b'everyday is Christmas'\n",
      " b'here with me']\n",
      "60\n",
      "[b'Nokia 7 Plus Specifications' b'safe in your arms' b'my angel baby'\n",
      " b'the gift that keeps']\n",
      "61\n",
      "[b'joy in my holiday song' b'And when you smile' b'I cant breathe'\n",
      " b'catch you tonight']\n",
      "62\n",
      "[b'keep you on ice' b'Snowflake you know' b'no one like you'\n",
      " b'Sony Xperia L2 With Wide-Angle Selfie Camera']\n",
      "63\n",
      "[b\"I'm gonna hide you\" b'Hello Airtel postpaid users' b'never leaving'\n",
      " b\"we'll be freezing\"]\n",
      "64\n",
      "[b'you are my home' b\"come on let's go\" b'go below zero'\n",
      " b'hide from the sun']\n",
      "65\n",
      "[b'hit the North Pole' b'live happily' b'carry me without legs'\n",
      " b'hear my secrets']\n",
      "66\n",
      "[b'Planets beyond Milky Way galaxy discovered for first time'\n",
      " b'Jeep Compass Trailhawk SUV' b'I love this song' b'I know you']\n",
      "67\n",
      "[b'youre a special one' b'Some see crazy' b'where I see love'\n",
      " b'You fall so low']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "[b'but shoot so high' b'So much life in those' b'you look for the light'\n",
      " b'when your wounds open']\n",
      "69\n",
      "[b\"'HTC U12' With 5G Support\" b'you will cry' b'I can see a rainbow'\n",
      " b'they fall on down']\n",
      "70\n",
      "[b'see your soul grow' b'Through the pain' b'they hit the ground'\n",
      " b'As the sun comes out']\n",
      "71\n",
      "[b'Through the storms' b'you cannot escape' b'You can do it'\n",
      " b'Renault Kwid Superhero Edition']\n",
      "72\n",
      "[b'just feel baby' b'turn the radio on'\n",
      " b\"Friday night and I won't be long\" b'Gotta do my hair']\n",
      "73\n",
      "[b'I hit the dance floor' b'I got all I need'\n",
      " b'dollar bills to have fun tonight' b'I love cheap thrills']\n",
      "74\n",
      "[b'I can feel the beat' b'God shaped hole leaves' b'iBall CompBook Premio'\n",
      " b\"friends won't bring relief\"]\n",
      "75\n",
      "[b'Drown your voice with party' b'For one and only'\n",
      " b'Faith creeps slowly over me' b'Took twelve steps']\n",
      "76\n",
      "[b'And carried me' b'Resurrection on me' b'Blunted thorns are soft'\n",
      " b'weight of life lift me']\n",
      "77\n",
      "[b'Hear the chatter fooling me'\n",
      " b'Google Flips the Switch on Its Pixel Visual Core' b'Drown your voice'\n",
      " b'I felt something light']\n",
      "78\n",
      "[b'A blinding white light' b'And I heard a cry' b'Burning to survive'\n",
      " b'We had love so strong']\n",
      "79\n",
      "[b'You took it in your hands' b'me and you against the world'\n",
      " b'you and me forever' b'felt every cell fall']\n",
      "80\n",
      "[b'Samsung Galaxy S9' b'I watched you slip' b'You on your phone'\n",
      " b'your laptop and your Playstation']\n",
      "81\n",
      "[b'stared at the diamond on my finger' b'But the truth never came'\n",
      " b'so see you later' b\"I won't miss you\"]\n",
      "82\n",
      "[b'you can treat another' b'rather walk alone'\n",
      " b'let them throw dirty confetti'\n",
      " b'India success propels Chinese smartphones']\n",
      "83\n",
      "[b'You hurt my pride' b'part of me died' b'the house we lived in'\n",
      " b'it had no windows']\n",
      "84\n",
      "[b'late to pay our bills' b\"wasn't my color\" b'Remember when we had'\n",
      " b'You were my whole world']\n",
      "85\n",
      "[b'a thing said to me' b'Question now'\n",
      " b'Intel made smart glasses that look normal' b'if my heart bleeds']\n",
      "86\n",
      "[b'customer who was charged for mobile repair under warranty period'\n",
      " b'free to be the greatest' b'the greatest alive' b'through the waves']\n",
      "87\n",
      "[b'hypnotise the whole room' b'happens on the edges' b'My seats come here'\n",
      " b'hit you with the wedges']\n",
      "88\n",
      "[b'come on make it turn' b'ready and you heard enough'\n",
      " b'Word travels fast' b'SpaceX Falcon Heavy Poised For Debut Test Launch']\n",
      "89\n",
      "[b\"Vivo V7+ Infinite Red 'Limited Edition' Launched in India\"\n",
      " b'move a lot of heads' b'fallen through the floor again'\n",
      " b'Crashed into the basement']\n",
      "90\n",
      "[b'pain was swallowing me' b'like a lead balloon' b'even get up to turn'\n",
      " b'The lights on']\n",
      "91\n",
      "[b\"can't trust your head\" b'standing on the edge' b'Of breaking down'\n",
      " b\"64 percent of antibiotic cocktails sold in India 'illegal'\"]\n",
      "92\n",
      "[b'hanging by a thread' b'I was breaking down' b'And I saw only two'\n",
      " b'footprints in the sand']\n",
      "93\n",
      "[b'abandoned me and' b'Let go of my hand' b'you were carrying me'\n",
      " b'forgot the things I knew']\n",
      "94\n",
      "[b'I was lost in doubt' b'Picked me up' b'Are you over 50?'\n",
      " b'You helped me']\n",
      "95\n",
      "[b'and I was found' b'Poetry in your body' b'got it in every way'\n",
      " b\"can't you see it's you\"]\n",
      "96\n",
      "[b'hot for you in every way' b'And turn around' b'free you with my rhythm'\n",
      " b\"you can't get enough\"]\n",
      "97\n",
      "[b'When I turn up with my' b\"The 'ripple effect' could have a huge impact\"\n",
      " b\"Your body's poetry\" b'Move your body']\n",
      "98\n",
      "[b'wanna be your muse' b'use my music' b'Got it started'\n",
      " b'may it never end']\n",
      "99\n",
      "[b'rhythm in your system' b'This is heaven' b\"I'm your only friend\"\n",
      " b'Feel the beat in your chest']\n",
      "100\n",
      "[b'20-month-olds ready to go home' b\"Free the beast from it's cage\"\n",
      " b'rage like an animal' b'Never ending symptoms']\n",
      "101\n",
      "[b'hollow in the emptiness' b'push you from the bed' b'No more fighting'\n",
      " b'stop watching my phone']\n",
      "102\n",
      "[b\"And you're to blame\" b'Feel the void' b'space between is deafening'\n",
      " b\"No one's moving\"]\n",
      "103\n",
      "[b'We lack the courage to'\n",
      " b'children in India not getting vaccinated on time'\n",
      " b'Wishing the other would' b\"don't like to wait too long\"]\n",
      "104\n",
      "[b'burning slow' b'feel the pain' b'it feels good' b'heart burns slow']\n",
      "105\n",
      "[b'I want to breathe you in' b'Like oxygen' b\"I'm a house on fire\"\n",
      " b'want to keep burning']\n",
      "106\n",
      "[b'These 4 lifestyle modifications can help you FIGHT cancer!'\n",
      " b'Going on up in flames'\n",
      " b'Natural remedies to get rid of that annoying migraine pain'\n",
      " b'This too shall pass']\n",
      "107\n",
      "[b\"things I don't ask\" b'I know what it takes' b'to fool this town'\n",
      " b'the sun goes down']\n",
      "108\n",
      "[b'all through the night time' b'what you wanna hear'\n",
      " b'Leave my sunglasses on' b'put my armor on']\n",
      "109\n",
      "[b'show you how strong' b'Cashews can improve good cholesterol levels'\n",
      " b\"I'm unstoppable\" b'Porsche with no brakes']\n",
      "110\n",
      "[b\"I'm invincible\" b'I win every single game' b\"I'm so powerful\"\n",
      " b\"don't need batteries to play\"]\n",
      "111\n",
      "[b'Hiding out deep down' b'let your feelings show'\n",
      " b'make friendships grow' b'News in Numbers']\n",
      "112\n",
      "[b'Mandatory For Students Wanting' b'Minimum temperature drops again'\n",
      " b'missing wife in West Bengal' b'banks get an ultimatum']\n",
      "113\n",
      "[b'January Home Sales' b'Accounts To Offer More Benefits'\n",
      " b'bank hit on rising bond yields' b'India to overtake Germany']\n",
      "114\n",
      "[b'gave me your trust' b'I want you safe' b\"I've got your back\"\n",
      " b'all freedom comes']\n",
      "115\n",
      "[b'Unprotected from the sun' b'me to sing you off' b\"don't forget us\"\n",
      " b'I were a betting man']\n",
      "116\n",
      "[b'now reach out to Xiaomi on WhatsApp' b\"Can't turn it off\"\n",
      " b'What is wrong with me?' b'if you change your mind']\n",
      "117\n",
      "[b'never much fun' b'nobody to catch your tears'\n",
      " b'we made some midnight decisions' b'God I hope']\n",
      "118\n",
      "[b'blur when we talk through' b'I wanna keep burning' b'the heavens now'\n",
      " b'as we are found']\n",
      "119\n",
      "[b'My heart screams out' b'to the beat of a drum'\n",
      " b'till the walls give in' b\"I don't wanna say\"]\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Unsupported object type NoneType\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING, DT_STRING], Tout=[DT_DOUBLE, DT_STRING, DT_INT64], token=\"pyfunc_0\"](arg0, arg1)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_DOUBLE, DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Unsupported object type NoneType\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING, DT_STRING], Tout=[DT_DOUBLE, DT_STRING, DT_INT64], token=\"pyfunc_0\"](arg0, arg1)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_DOUBLE, DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ecfd6a8596ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m: Unsupported object type NoneType\n\t [[Node: PyFunc = PyFunc[Tin=[DT_STRING, DT_STRING], Tout=[DT_DOUBLE, DT_STRING, DT_INT64], token=\"pyfunc_0\"](arg0, arg1)]]\n\t [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[<unknown>, <unknown>, <unknown>], output_types=[DT_DOUBLE, DT_STRING, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](Iterator)]]"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(iterator.initializer)\n",
    "    for i in range(500):\n",
    "      value = sess.run(item[1])\n",
    "      print(i)\n",
    "      print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([  num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "   # x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # Get lstm cell output\n",
    "   # outputs, _, _ = rnn.static_bidirectional_rnn(lstm_cell , x,\n",
    "    #dtype=tf.float32)\n",
    "    \n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=lstm_cell,\n",
    "                                   inputs=x,\n",
    "                                   sequence_length=seq_len,\n",
    "                                   dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    #convert output shape (timesteps * batch * hidden units ) to (batch*timesteps* hidden units)\n",
    "    outputs=tf.transpose( outputs , [1, 0, 2])\n",
    "    \n",
    "    outputs=tf.reshape(outputs, [-1,num_hidden])\n",
    "    \n",
    "  \n",
    "    res =  tf.matmul(outputs, weights['out']) + biases['out']\n",
    "    \n",
    "    res = tf.reshape(res, [batch_size,timesteps,num_classes])\n",
    "    \n",
    "    # new code \n",
    "    # state is of shape ( batch size ,  hidden_units)\n",
    "    # need to adapt weights accordingly \n",
    "    \n",
    "    \n",
    "    return res\n",
    "   # return tf.nn.softmax(tf.matmul(outputs, weights['out']) + biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "logits = RNN(inputs, weights, biases)\n",
    "\n",
    "loss =  tf.nn.ctc_loss ( targets, logits , seq_len , time_major = False)\n",
    "cost = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                           0.9).minimize(cost)\n",
    "\n",
    "\n",
    "# Option 2: tf.contrib.ctc.ctc_beam_search_decoder\n",
    "    # (it's slower but you'll get better results)\n",
    "decoder_input = tf.transpose(logits, [1, 0, 2])\n",
    "\n",
    "decoded, log_prob = tf.nn.ctc_greedy_decoder(decoder_input, seq_len)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Saver' op to save and restore all the variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need this for decoding word give its index key value \n",
    "\n",
    "def keys_of_value(dct, value):\n",
    "    for k in dct:\n",
    "        if isinstance(dct[k], list):\n",
    "            if value in dct[k]:\n",
    "                return k\n",
    "        else:\n",
    "            if value == dct[k]:\n",
    "                return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing above function \n",
    "\n",
    "print(keys_of_value(word_dictionary, 2419))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain from a checkpoint\n",
    "# if training first time, ignore this block\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "        \n",
    "    # Restore model weights from previously saved model\n",
    "    load_path = saver.restore(sess, model_path +  '/2' )\n",
    "    print(\"Model restored from file: %s\" % load_path)\n",
    "    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_steps):\n",
    "     #   avg_cost = 0.\n",
    "           # Save model weights to disk\n",
    "        save_path = saver.save(sess, model_path +  '/2')\n",
    "        print(\"Model saved in file: %s\" % save_path) \n",
    "        \n",
    "        \n",
    "        sess.run(iterator.initializer)\n",
    "        train_cost=0\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                Next_element=sess.run(item)\n",
    "             \n",
    "            \n",
    "                 \n",
    "                print(Next_element[1])   \n",
    "                \n",
    "                batch_list = []\n",
    "                \n",
    " \n",
    "                for index,j in enumerate(Next_element[1]):\n",
    "                    batch_list.insert(index, word_to_index(j.decode(\"utf-8\")))\n",
    "                    \n",
    "                \n",
    "                batch_targets = sparse_tuple_from(batch_list)\n",
    "                \n",
    "                print(Next_element[2])\n",
    "                \n",
    "                feed = {inputs: Next_element[0],\n",
    "                        targets: batch_targets,\n",
    "                        seq_len: Next_element[2],\n",
    "                         }\n",
    "\t    \n",
    "\n",
    "                batch_cost, _ , summary = sess.run([cost, optimizer , merged_summary_op ], feed)\n",
    "               # print(batch_cost)\n",
    "                \n",
    "                train_cost += batch_cost*batch_size\n",
    "                \n",
    "                \n",
    "                # Write logs at every iteration\n",
    "                summary_writer.add_summary(summary, epoch )\n",
    "                \n",
    "                 # Decoding\n",
    "                d = sess.run(decoded[0], feed_dict=feed)\n",
    "   \n",
    "                dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=sess)\n",
    "    \n",
    "                for i, seq in enumerate(dense_decoded):\n",
    "\n",
    "                    seq = [s for s in seq if s != -1]\n",
    "       \n",
    "                    str_decoded = ''.join([keys_of_value(word_dictionary, x) for x in seq ])\n",
    "                    print(str_decoded)\n",
    "            \n",
    "              \n",
    "            except tf.errors.OutOfRangeError:\n",
    "              print(train_cost)\n",
    "              \n",
    "              \n",
    "              break\n",
    "                \n",
    "        # Save model weights to disk at the end of all epochs, if we remove this last epoch doesnt gets saved\n",
    "    save_path = saver.save(sess, model_path +  '/2')\n",
    "    print(\"Model saved in file: %s\" % save_path)        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_steps):\n",
    "     #   avg_cost = 0.\n",
    "           # Save model weights to disk\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        print(\"Model saved in file: %s\" % save_path) \n",
    "        \n",
    "        \n",
    "        sess.run(iterator.initializer)\n",
    "        train_cost=0\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                Next_element=sess.run(item)\n",
    "             \n",
    "            \n",
    "                 \n",
    "                print(Next_element[1])   \n",
    "                \n",
    "                batch_list = []\n",
    "                \n",
    " \n",
    "                for index,j in enumerate(Next_element[1]):\n",
    "                    batch_list.insert(index, word_to_index(j.decode(\"utf-8\")))\n",
    "                    \n",
    "                \n",
    "                batch_targets = sparse_tuple_from(batch_list)\n",
    "                \n",
    "                print(Next_element[2])\n",
    "                \n",
    "                feed = {inputs: Next_element[0],\n",
    "                        targets: batch_targets,\n",
    "                        seq_len: Next_element[2],\n",
    "                         }\n",
    "\t    \n",
    "\n",
    "                batch_cost, _ , summary = sess.run([cost, optimizer , merged_summary_op ], feed)\n",
    "               # print(batch_cost)\n",
    "                \n",
    "                train_cost += batch_cost*batch_size\n",
    "                \n",
    "                \n",
    "                # Write logs at every iteration\n",
    "                summary_writer.add_summary(summary, epoch )\n",
    "                \n",
    "                 # Decoding\n",
    "                d = sess.run(decoded[0], feed_dict=feed)\n",
    "   \n",
    "                dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=sess)\n",
    "    \n",
    "                for i, seq in enumerate(dense_decoded):\n",
    "\n",
    "                    seq = [s for s in seq if s != -1]\n",
    "       \n",
    "                    str_decoded = ''.join([keys_of_value(word_dictionary, x) for x in seq ])\n",
    "                    print(str_decoded)\n",
    "            \n",
    "              \n",
    "            except tf.errors.OutOfRangeError:\n",
    "              print(train_cost)\n",
    "              \n",
    "              \n",
    "              break\n",
    "                \n",
    "        # Save model weights to disk at the end of all epochs, if we remove this last epoch doesnt gets saved\n",
    "    save_path = saver.save(sess, model_path)\n",
    "    print(\"Model saved in file: %s\" % save_path)         \n",
    "\n",
    "               \n",
    "        \n",
    "            \n",
    "                \n",
    "                \n",
    "             \n",
    "                \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_orange",
   "language": "python",
   "name": "tf_orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
