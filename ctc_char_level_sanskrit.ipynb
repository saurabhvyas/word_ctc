{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  word level CTC  tensorflow version 1.3\n",
    "\n",
    "# this module requires the following :\n",
    "\n",
    "#  a dataset csv file ( have a look at dataset csv generator)\n",
    "#  a dictionary.txt file ( have a look at dictionary folder)\n",
    "\n",
    "\n",
    "\n",
    "# to do :   \n",
    "#   , get rid of fixed batch size , instead use variable batch size  \n",
    "\n",
    "\n",
    "# perform following tests :\n",
    "\n",
    "# 1. variable batch sizes test\n",
    "# 2. GPU test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# please change the following according to your system\n",
    "# hyperparameters in this notebook\n",
    "\n",
    "# change paths in this notebook to that corresponding to your system\n",
    "# please note number of audio examples in dataset must be even \n",
    "\n",
    "# peace.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saurabh/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from tensorflow.contrib.data import Dataset, Iterator\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audio_to_mfcc(fileurl):\n",
    "    rate, sig = wav.read(fileurl)\n",
    "    mfcc_feat = mfcc(sig,rate, nfilt=55,numcep=15)\n",
    "#d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "#fbank_feat = logfbank(sig,rate)\n",
    "\n",
    "    return mfcc_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalized(a, axis=-1, order=2):\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2==0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "targets={}\n",
    "# Constants\n",
    "#SPACE_TOKEN = '<space>'\n",
    "#SPACE_INDEX = 0\n",
    "#FIRST_INDEX = ord('a') - 96  # 0 is reserved to space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = audio_to_mfcc('/home/saurabh/Documents/tf_orange/tf_orange/data/test.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_csv(line):\n",
    "       parsed_line = tf.decode_csv(line, [[\"\"],[\"\"]])\n",
    "       \n",
    "    \n",
    "       \n",
    "       \n",
    "\n",
    "       return parsed_line[0] , parsed_line[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function is required for CTC Loss\n",
    "# for it's input , first convert transcrition / ground truth to number representation \n",
    "\n",
    "def sparse_tuple_from(sequences, dtype=np.int32):\n",
    "    \"\"\"Create a sparse representention of x.\n",
    "    Args:\n",
    "        sequences: a list of lists of type dtype where each element is a sequence\n",
    "    Returns:\n",
    "        A tuple with (indices, values, shape)\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    values = []\n",
    "\n",
    "    for n, seq in enumerate(sequences):\n",
    "        indices.extend(zip([n]*len(seq), range(len(seq))))\n",
    "        values.extend(seq)\n",
    "\n",
    "    indices = np.asarray(indices, dtype=np.int64)\n",
    "    values = np.asarray(values, dtype=dtype)\n",
    "    shape = np.asarray([len(sequences), np.asarray(indices).max(0)[1]+1], dtype=np.int64)\n",
    "\n",
    "    return indices, values, shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_txt_file='/media/saurabh/New Volume2/hindi_char/sanskrit/data_backup/sanskrit_final.txt'\n",
    "with open(input_txt_file, 'r', encoding='utf-16le') as myfile:\n",
    "    data=myfile.read() #.replace('\\n', '')\n",
    "graphemes={}\n",
    "from uniseg.graphemecluster import grapheme_clusters\n",
    "graphemes_list=[]\n",
    "for i in grapheme_clusters(data):\n",
    "    graphemes_list.append(i)\n",
    "\n",
    "graphemes_list=list(set(graphemes_list))\n",
    "print(len(graphemes_list))\n",
    "for i,j in enumerate(graphemes_list):\n",
    "    #print(i)\n",
    "    graphemes[j]=i\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_black_list = \"!@#$?.,|:()1234567890\"\n",
    "\n",
    "def remove_blacklisted_chars(input):\n",
    "    for char in char_black_list:\n",
    "        input = input.replace(char,\"\")\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_grapheme(sentence):\n",
    "    input_sentence_list=[]\n",
    "    for i in grapheme_clusters(sentence):\n",
    "    #input_sentence_list.append(i)\n",
    "     # return dictionary value of i\n",
    "        \n",
    "        #print(i)\n",
    "        \n",
    "        input_sentence_list.append(graphemes[i])\n",
    "    return input_sentence_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 21,\n",
       " 49,\n",
       " 67,\n",
       " 58,\n",
       " 35,\n",
       " 53,\n",
       " 33,\n",
       " 35,\n",
       " 34,\n",
       " 74,\n",
       " 50,\n",
       " 16,\n",
       " 35,\n",
       " 8,\n",
       " 34,\n",
       " 74,\n",
       " 50,\n",
       " 67,\n",
       " 58,\n",
       " 35,\n",
       " 53,\n",
       " 88]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = u\"अधनस्य कुतो मित्रम्, अमित्रस्य कुतः\"\n",
    "\n",
    "sentence_to_grapheme(remove_blacklisted_chars(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['रा',\n",
       " 'री',\n",
       " 'ष्',\n",
       " 'दी',\n",
       " 'थो',\n",
       " 'स',\n",
       " 'नु',\n",
       " 'व',\n",
       " 'अ',\n",
       " 'आ',\n",
       " 'र्',\n",
       " 'न्',\n",
       " 'उ',\n",
       " 'रि',\n",
       " 'धः',\n",
       " 'ग',\n",
       " 'म्',\n",
       " 'दा',\n",
       " 'सु',\n",
       " 'टा',\n",
       " 'टु',\n",
       " 'ध',\n",
       " 'वं',\n",
       " 'नं',\n",
       " 'त',\n",
       " 'रु',\n",
       " ',',\n",
       " 'ये',\n",
       " 'पि',\n",
       " 'सू',\n",
       " 'घु',\n",
       " 'थ',\n",
       " 'या',\n",
       " 'तो',\n",
       " 'मि',\n",
       " ' ',\n",
       " 'धै',\n",
       " 'प',\n",
       " '\\ufeff',\n",
       " 'ध्',\n",
       " 'घ',\n",
       " 'वि',\n",
       " 'रो',\n",
       " 'द्',\n",
       " 'नि',\n",
       " 'दै',\n",
       " 'ख',\n",
       " 'जः',\n",
       " 'नां',\n",
       " 'न',\n",
       " 'र',\n",
       " 'का',\n",
       " 'ना',\n",
       " 'कु',\n",
       " 'रे',\n",
       " 'लो',\n",
       " 'णे',\n",
       " 'ब',\n",
       " 'य',\n",
       " 'हि',\n",
       " 'लं',\n",
       " 'व्',\n",
       " 'पुः',\n",
       " 'के',\n",
       " 'ल',\n",
       " 'ति',\n",
       " 'माः',\n",
       " 'स्',\n",
       " 'यं',\n",
       " 'क',\n",
       " 'तु',\n",
       " 'ह्',\n",
       " 'ता',\n",
       " 'द',\n",
       " 'त्',\n",
       " '\\xa0',\n",
       " 'हा',\n",
       " 'था',\n",
       " 'ए',\n",
       " 'सि',\n",
       " 'च',\n",
       " 'सा',\n",
       " 'म',\n",
       " 'क्',\n",
       " 'श',\n",
       " 'चे',\n",
       " 'भ',\n",
       " 'णां',\n",
       " 'तः',\n",
       " 'ण',\n",
       " 'शी',\n",
       " 'वे',\n",
       " 'पु',\n",
       " 'षु',\n",
       " 'ष']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphemes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 35,\n",
       " ',': 26,\n",
       " '\\xa0': 75,\n",
       " 'अ': 8,\n",
       " 'आ': 9,\n",
       " 'उ': 12,\n",
       " 'ए': 78,\n",
       " 'क': 69,\n",
       " 'का': 51,\n",
       " 'कु': 53,\n",
       " 'के': 63,\n",
       " 'क्': 83,\n",
       " 'ख': 46,\n",
       " 'ग': 15,\n",
       " 'घ': 40,\n",
       " 'घु': 30,\n",
       " 'च': 80,\n",
       " 'चे': 85,\n",
       " 'जः': 47,\n",
       " 'टा': 19,\n",
       " 'टु': 20,\n",
       " 'ण': 89,\n",
       " 'णां': 87,\n",
       " 'णे': 56,\n",
       " 'त': 24,\n",
       " 'तः': 88,\n",
       " 'ता': 72,\n",
       " 'ति': 65,\n",
       " 'तु': 70,\n",
       " 'तो': 33,\n",
       " 'त्': 74,\n",
       " 'थ': 31,\n",
       " 'था': 77,\n",
       " 'थो': 4,\n",
       " 'द': 73,\n",
       " 'दा': 17,\n",
       " 'दी': 3,\n",
       " 'दै': 45,\n",
       " 'द्': 43,\n",
       " 'ध': 21,\n",
       " 'धः': 14,\n",
       " 'धै': 36,\n",
       " 'ध्': 39,\n",
       " 'न': 49,\n",
       " 'नं': 23,\n",
       " 'ना': 52,\n",
       " 'नां': 48,\n",
       " 'नि': 44,\n",
       " 'नु': 6,\n",
       " 'न्': 11,\n",
       " 'प': 37,\n",
       " 'पि': 28,\n",
       " 'पु': 92,\n",
       " 'पुः': 62,\n",
       " 'ब': 57,\n",
       " 'भ': 86,\n",
       " 'म': 82,\n",
       " 'माः': 66,\n",
       " 'मि': 34,\n",
       " 'म्': 16,\n",
       " 'य': 58,\n",
       " 'यं': 68,\n",
       " 'या': 32,\n",
       " 'ये': 27,\n",
       " 'र': 50,\n",
       " 'रा': 0,\n",
       " 'रि': 13,\n",
       " 'री': 1,\n",
       " 'रु': 25,\n",
       " 'रे': 54,\n",
       " 'रो': 42,\n",
       " 'र्': 10,\n",
       " 'ल': 64,\n",
       " 'लं': 60,\n",
       " 'लो': 55,\n",
       " 'व': 7,\n",
       " 'वं': 22,\n",
       " 'वि': 41,\n",
       " 'वे': 91,\n",
       " 'व्': 61,\n",
       " 'श': 84,\n",
       " 'शी': 90,\n",
       " 'ष': 94,\n",
       " 'षु': 93,\n",
       " 'ष्': 2,\n",
       " 'स': 5,\n",
       " 'सा': 81,\n",
       " 'सि': 79,\n",
       " 'सु': 18,\n",
       " 'सू': 29,\n",
       " 'स्': 67,\n",
       " 'हा': 76,\n",
       " 'हि': 59,\n",
       " 'ह्': 71,\n",
       " '\\ufeff': 38}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function, that pads audio so that audio frames = max frames\n",
    "\n",
    "def pad(input):\n",
    "   # print(input.shape[0])\n",
    "     if input.shape[0] < timesteps:\n",
    "        \n",
    "        diff = timesteps - input.shape[0]\n",
    "        \n",
    "        # pad and return input\n",
    "        return np.pad(input,((0,diff),(0,0)), mode=\"constant\")\n",
    "    \n",
    "     elif input.shape[0] > timesteps:\n",
    "        \n",
    "        return input[:timesteps,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _read_py_function(audio, label):\n",
    "    audio = audio_to_mfcc(audio)\n",
    "    \n",
    "    if audio.shape[0] < timesteps:\n",
    "        original_length=audio.shape[0]\n",
    "       # print(original_length)\n",
    "    \n",
    "    elif audio.shape[0] >= timesteps:\n",
    "        original_length=timesteps\n",
    "        \n",
    "    #audio=normalized(pad(audio) , axis=1 )\n",
    "    audio=pad(audio)\n",
    "   \n",
    "    return audio ,label, original_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-5b4fb2f2144b>:1: TextLineDataset.__init__ (from tensorflow.contrib.data.python.ops.readers) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.TextLineDataset`.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.contrib.data.TextLineDataset(\"/home/saurabh/Documents/tf_orange/tf_orange/sanskrit.csv\")\n",
    "dataset=dataset.map(decode_csv)\n",
    "\n",
    "\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda audio, label: tuple(tf.py_func(\n",
    "        _read_py_function, [audio, label], [tf.double, label.dtype, tf.int64])))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dataset=dataset.batch(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "item = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.01\n",
    "training_steps = 100\n",
    "#batch_size = 2\n",
    "display_step = 200\n",
    "num_features = 15\n",
    "beta=0.01\n",
    "logs_path = '/home/saurabh/Documents/tf_orange/tf_orange/hardik/logs'\n",
    "model_path = '/home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt'\n",
    "\n",
    "# Network Parameters\n",
    "\n",
    "timesteps = 300 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "\n",
    "num_classes = len(graphemes_list) + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prediction = tf.nn.softmax(logits)\n",
    "inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "targets = tf.sparse_placeholder(tf.int32)\n",
    "seq_len = tf.placeholder(tf.int32, [None])\n",
    "batch_size = 2\n",
    "\n",
    "#batch_size = tf.placeholder ( tf.int32 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([  2 * num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]), name='bias')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Define weights\\nweights = {\\n    'out': tf.Variable(tf.random_normal([  num_hidden, num_classes]))\\n}\\nbiases = {\\n    'out': tf.Variable(tf.random_normal([num_classes]), name='bias')\\n}\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([  num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]), name='bias')\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell_fw = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "    lstm_cell_bw = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    \n",
    "    # Get lstm cell output\n",
    "    outputs, _, _ = rnn.static_bidirectional_rnn(lstm_cell_fw, lstm_cell_bw, x,\n",
    "    dtype=tf.float32)\n",
    "    \n",
    "    #convert output shape (timesteps * batch * classes ) to (batch*timesteps*classes)\n",
    "    outputs=tf.transpose( outputs , [1, 0, 2])\n",
    "    \n",
    "    outputs=tf.reshape(outputs, [-1,2*num_hidden])\n",
    "    \n",
    "  \n",
    "    res =  tf.matmul(outputs, weights['out']) + biases['out']\n",
    "    \n",
    "    res = tf.reshape(res, [batch_size,timesteps,num_classes])\n",
    "    \n",
    "    return res\n",
    "   # return tf.nn.softmax(tf.matmul(outputs, weights['out']) + biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def RNN(x, weights, biases):\\n\\n    # Prepare data shape to match `rnn` function requirements\\n    # Current data input shape: (batch_size, timesteps, n_input)\\n    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\\n\\n    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\\n   # x = tf.unstack(x, timesteps, 1)\\n\\n    # Define a lstm cell with tensorflow\\n    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\\n    \\n    \\n\\n    \\n    # Get lstm cell output\\n   # outputs, _, _ = rnn.static_bidirectional_rnn(lstm_cell , x,\\n    #dtype=tf.float32)\\n    \\n    outputs, state = tf.nn.dynamic_rnn(cell=lstm_cell,\\n                                   inputs=x,\\n                                   sequence_length=seq_len,\\n                                   dtype=tf.float32)\\n    \\n    \\n    #convert output shape (timesteps * batch * hidden units ) to (batch*timesteps* hidden units)\\n    outputs=tf.transpose( outputs , [1, 0, 2])\\n    \\n    outputs=tf.reshape(outputs, [-1,num_hidden])\\n    \\n  \\n    res =  tf.matmul(outputs, weights['out']) + biases['out']\\n    \\n    res = tf.reshape(res, [batch_size,timesteps,num_classes])\\n    \\n    # new code \\n    # state is of shape ( batch size ,  hidden_units)\\n    # need to adapt weights accordingly \\n    \\n    \\n    return res\\n   # return tf.nn.softmax(tf.matmul(outputs, weights['out']) + biases['out']) \""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "   # x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # Get lstm cell output\n",
    "   # outputs, _, _ = rnn.static_bidirectional_rnn(lstm_cell , x,\n",
    "    #dtype=tf.float32)\n",
    "    \n",
    "    outputs, state = tf.nn.dynamic_rnn(cell=lstm_cell,\n",
    "                                   inputs=x,\n",
    "                                   sequence_length=seq_len,\n",
    "                                   dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    #convert output shape (timesteps * batch * hidden units ) to (batch*timesteps* hidden units)\n",
    "    outputs=tf.transpose( outputs , [1, 0, 2])\n",
    "    \n",
    "    outputs=tf.reshape(outputs, [-1,num_hidden])\n",
    "    \n",
    "  \n",
    "    res =  tf.matmul(outputs, weights['out']) + biases['out']\n",
    "    \n",
    "    res = tf.reshape(res, [batch_size,timesteps,num_classes])\n",
    "    \n",
    "    # new code \n",
    "    # state is of shape ( batch size ,  hidden_units)\n",
    "    # need to adapt weights accordingly \n",
    "    \n",
    "    \n",
    "    return res\n",
    "   # return tf.nn.softmax(tf.matmul(outputs, weights['out']) + biases['out']) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "logits = RNN(inputs, weights, biases)\n",
    "\n",
    "loss =  tf.nn.ctc_loss ( targets, logits , seq_len , time_major = False)\n",
    "cost = tf.reduce_mean(loss)\n",
    "\n",
    "tv = tf.trainable_variables()\n",
    "variables_names = [v.name for v in tf.trainable_variables()]\n",
    "\n",
    "reg = tf.reduce_sum([ tf.nn.l2_loss(v) for v in tv if 'bias' not in v.name])\n",
    "\n",
    "total_loss = tf.reduce_mean(cost + reg * beta)\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                           0.9).minimize(total_loss)\n",
    "\n",
    "gradient_optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "adam_optimizer = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "\n",
    "\n",
    "# Option 2: tf.contrib.ctc.ctc_beam_search_decoder\n",
    "    # (it's slower but you'll get better results)\n",
    "decoder_input = tf.transpose(logits, [1, 0, 2])\n",
    "\n",
    "decoded, log_prob = tf.nn.ctc_greedy_decoder(decoder_input, seq_len)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", cost)\n",
    "\n",
    "# Merge all summaries into a single op\n",
    "merged_summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Saver' op to save and restore all the variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need this for decoding word give its index key value \n",
    "\n",
    "def keys_of_value(dct, value):\n",
    "    for k in dct:\n",
    "        if isinstance(dct[k], list):\n",
    "            if value in dct[k]:\n",
    "                return k\n",
    "        else:\n",
    "            if value == dct[k]:\n",
    "                return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_dictionary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-6e7b486056f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# testing above function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys_of_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_dictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2419\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_dictionary' is not defined"
     ]
    }
   ],
   "source": [
    "# testing above function \n",
    "\n",
    "print(keys_of_value(word_dictionary, 2419))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to get matching files on /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt/2: Not found: /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt; No such file or directory\n\t [[Node: save/RestoreV2_25 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_25/tensor_names, save/RestoreV2_25/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_25', defined at:\n  File \"/home/saurabh/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/saurabh/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-01d2462a7cf0>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1239, in __init__\n    self.build()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1248, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1284, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 765, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 428, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 268, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1031, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt/2: Not found: /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt; No such file or directory\n\t [[Node: save/RestoreV2_25 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_25/tensor_names, save/RestoreV2_25/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt/2: Not found: /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt; No such file or directory\n\t [[Node: save/RestoreV2_25 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_25/tensor_names, save/RestoreV2_25/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-ec756405dbef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Restore model weights from previously saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mload_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m'/2'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model restored from file: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mload_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1684\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1686\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1687\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt/2: Not found: /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt; No such file or directory\n\t [[Node: save/RestoreV2_25 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_25/tensor_names, save/RestoreV2_25/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_25', defined at:\n  File \"/home/saurabh/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/saurabh/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-28-01d2462a7cf0>\", line 2, in <module>\n    saver = tf.train.Saver()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1239, in __init__\n    self.build()\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1248, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1284, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 765, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 428, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 268, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1031, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/home/saurabh/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to get matching files on /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt/2: Not found: /home/saurabh/Documents/tf_orange/tf_orange/models/hardik/lite/model.ckpt; No such file or directory\n\t [[Node: save/RestoreV2_25 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_25/tensor_names, save/RestoreV2_25/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "# retrain from a checkpoint\n",
    "# if training first time, ignore this block\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "        \n",
    "    # Restore model weights from previously saved model\n",
    "    load_path = saver.restore(sess, model_path +  '/2' )\n",
    "    print(\"Model restored from file: %s\" % load_path)\n",
    "    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_steps):\n",
    "     #   avg_cost = 0.\n",
    "           # Save model weights to disk\n",
    "        save_path = saver.save(sess, model_path +  '/2')\n",
    "        print(\"Model saved in file: %s\" % save_path) \n",
    "        \n",
    "        \n",
    "        sess.run(iterator.initializer)\n",
    "        train_cost=0\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                Next_element=sess.run(item)\n",
    "             \n",
    "            \n",
    "                 \n",
    "                print(Next_element[1])   \n",
    "                \n",
    "                batch_list = []\n",
    "                \n",
    " \n",
    "                for index,j in enumerate(Next_element[1]):\n",
    "                    batch_list.insert(index, )\n",
    "                    \n",
    "                \n",
    "                batch_targets = sparse_tuple_from(batch_list)\n",
    "                \n",
    "                print(Next_element[2])\n",
    "                \n",
    "                feed = {inputs: Next_element[0],\n",
    "                        targets: batch_targets,\n",
    "                        seq_len: Next_element[2],\n",
    "                         }\n",
    "\t    \n",
    "\n",
    "                batch_cost, _ , summary = sess.run([cost, adam_optimizer , merged_summary_op ], feed)\n",
    "               # print(batch_cost)\n",
    "                \n",
    "                train_cost += batch_cost*batch_size\n",
    "                \n",
    "                \n",
    "                # Write logs at every iteration\n",
    "                summary_writer.add_summary(summary, epoch )\n",
    "                \n",
    "                 # Decoding\n",
    "                d = sess.run(decoded[0], feed_dict=feed)\n",
    "   \n",
    "                dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=sess)\n",
    "    \n",
    "                for i, seq in enumerate(dense_decoded):\n",
    "\n",
    "                    seq = [s for s in seq if s != -1]\n",
    "       \n",
    "                    #str_decoded = ''.join([keys_of_value(word_dictionary, x) for x in seq ])\n",
    "                    #print(str_decoded)\n",
    "            \n",
    "              \n",
    "            except tf.errors.OutOfRangeError:\n",
    "              print(train_cost)\n",
    "              \n",
    "              \n",
    "              break\n",
    "                \n",
    "        # Save model weights to disk at the end of all epochs, if we remove this last epoch doesnt gets saved\n",
    "    save_path = saver.save(sess, model_path +  '/2')\n",
    "    print(\"Model saved in file: %s\" % save_path)        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # op to write logs to Tensorboard\n",
    "    summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_steps):\n",
    "     #   avg_cost = 0.\n",
    "           # Save model weights to disk\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        print(\"Model saved in file: %s\" % save_path) \n",
    "        \n",
    "        \n",
    "        sess.run(iterator.initializer)\n",
    "        train_cost=0\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                Next_element=sess.run(item)\n",
    "             \n",
    "            \n",
    "                 \n",
    "                #print(Next_element[1].decode(\"utf-8\"))   \n",
    "                \n",
    "                #batch_list=np.zeros(2)\n",
    "                \n",
    "                batch_list = []\n",
    "                \n",
    " \n",
    "                for index,j in enumerate(Next_element[1]):\n",
    "                    batch_list.insert(index, sentence_to_grapheme(j.decode(\"utf-8\")))\n",
    "                    \n",
    "                \n",
    "                batch_targets = sparse_tuple_from(batch_list)\n",
    "                \n",
    "                #batch_list =  sentence_to_char_array(Next_element[1][0].decode(\"utf-8\"))\n",
    "                    \n",
    "                \n",
    "                #batch_targets = sparse_tuple_from(batch_list)\n",
    "                print(batch_list)\n",
    "                \n",
    "                print(Next_element[2])\n",
    "                \n",
    "                feed = {inputs: Next_element[0],\n",
    "                        targets: batch_targets,\n",
    "                        seq_len: Next_element[2],\n",
    "                         }\n",
    "\t    \n",
    "\n",
    "                batch_cost, _ , summary = sess.run([cost, gradient_optimizer , merged_summary_op ], feed)\n",
    "               # print(batch_cost)\n",
    "                \n",
    "                train_cost += batch_cost*batch_size\n",
    "                \n",
    "                \n",
    "                # Write logs at every iteration\n",
    "                summary_writer.add_summary(summary, epoch )\n",
    "                \n",
    "                 # Decoding\n",
    "                d = sess.run(decoded[0], feed_dict=feed)\n",
    "   \n",
    "                dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=sess)\n",
    "    \n",
    "                for i, seq in enumerate(dense_decoded):\n",
    "\n",
    "                    seq = [s for s in seq if s != -1]\n",
    "                \n",
    "                    #print(seq)\n",
    "       \n",
    "                    str_decoded = ''.join([ graphemes_list[x]  for x in seq ])\n",
    "                    print('decoded :' + str_decoded)\n",
    "            \n",
    "              \n",
    "            except tf.errors.OutOfRangeError:\n",
    "              print(train_cost)\n",
    "              \n",
    "              \n",
    "              break\n",
    "                \n",
    "        # Save model weights to disk at the end of all epochs, if we remove this last epoch doesnt gets saved\n",
    "    save_path = saver.save(sess, model_path)\n",
    "    print(\"Model saved in file: %s\" % save_path)         \n",
    "\n",
    "               \n",
    "        \n",
    "            \n",
    "                \n",
    "                \n",
    "             \n",
    "                \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_orange",
   "language": "python",
   "name": "tf_orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
