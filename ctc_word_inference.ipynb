{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# used pretrained model to perform inference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from tensorflow.contrib import rnn\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from tensorflow.contrib.data import Dataset, Iterator\n",
    "\n",
    "model_path = \"/home/saurabh/Documents/tf_orange/tf_orange/models/model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def audio_to_mfcc(fileurl):\n",
    "    rate, sig = wav.read(fileurl)\n",
    "    mfcc_feat = mfcc(sig,rate)\n",
    "#d_mfcc_feat = delta(mfcc_feat, 2)\n",
    "#fbank_feat = logfbank(sig,rate)\n",
    "\n",
    "    return mfcc_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we also need a fixed vocabulary \n",
    "import re\n",
    "\n",
    "word_dictionary = {}\n",
    "\n",
    "with open(\"/home/saurabh/Documents/tf_orange/tf_orange/words/words.txt\") as file:\n",
    "    for i , line in enumerate(file):\n",
    "        \n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        word_dictionary[line] = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.001\n",
    "training_steps = 5\n",
    "batch_size = 1\n",
    "display_step = 200\n",
    "num_features = 13\n",
    "\n",
    "\n",
    "num_classes = 9 # words.txt , all words plus space word  ( 10001) + CTC symbol (1)\n",
    "timesteps = 300 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word_to_index(sentence):\n",
    "   \n",
    "    words = sentence.split(' ')\n",
    "    index_list=[]\n",
    "    for word in words:\n",
    "       \n",
    "        if word in word_dictionary:\n",
    "           # print(word)\n",
    "            index_list.insert(len(index_list) , word_dictionary[word])\n",
    "            index_list.insert(len(index_list) , word_dictionary[' '])\n",
    "    index_list.pop()        \n",
    "    return index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell_fw = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "    \n",
    "    lstm_cell_bw = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    \n",
    "    # Get lstm cell output\n",
    "    outputs, _, _ = rnn.static_bidirectional_rnn(lstm_cell_fw, lstm_cell_bw, x,\n",
    "    dtype=tf.float32)\n",
    "    \n",
    "    #convert output shape (timesteps * batch * classes ) to (batch*timesteps*classes)\n",
    "    outputs=tf.transpose( outputs , [1, 0, 2])\n",
    "    \n",
    "    \n",
    "    \n",
    "  \n",
    "    res =  tf.matmul(outputs, weights['out']) + biases['out']\n",
    "    \n",
    "    return res\n",
    "   # return tf.nn.softmax(tf.matmul(outputs, weights['out']) + biases['out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([batch_size, 2 * num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = tf.nn.softmax(logits)\n",
    "inputs = tf.placeholder(tf.float32, [None, None, num_features])\n",
    "targets = tf.sparse_placeholder(tf.int32)\n",
    "seq_len = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logits = RNN(inputs, weights, biases)\n",
    "\n",
    "loss =  tf.nn.ctc_loss ( targets, logits , seq_len , time_major = False)\n",
    "cost = tf.reduce_mean(loss)\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate,\n",
    "                                           0.9).minimize(cost)\n",
    "\n",
    "\n",
    "# Option 2: tf.contrib.ctc.ctc_beam_search_decoder\n",
    "    # (it's slower but you'll get better results)\n",
    "decoder_input = tf.transpose(logits, [1, 0, 2])\n",
    "\n",
    "decoded, log_prob = tf.nn.ctc_greedy_decoder(decoder_input, seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need this for decoding word give its index key value \n",
    "\n",
    "def keys_of_value(dct, value):\n",
    "    for k in dct:\n",
    "        if isinstance(dct[k], list):\n",
    "            if value in dct[k]:\n",
    "                return k\n",
    "        else:\n",
    "            if value == dct[k]:\n",
    "                return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    hello anotherworldais isaworldworld    test     atestaisaanotheraisaisaisatestisworld   test test \n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "\n",
    "    # Run the initializer\n",
    "                sess.run(init)\n",
    "    \n",
    "                \n",
    "                max_len=timesteps\n",
    "                    \n",
    "                                 \n",
    "                temp_np_inputs = np.zeros((batch_size , max_len , 13 ))\n",
    "                    \n",
    "                test_item = audio_to_mfcc('/home/saurabh/Documents/tf_orange/tf_orange/data/test.wav')\n",
    "                \n",
    "                batch_lengths=[test_item.shape[0]]\n",
    "                \n",
    "                if test_item.shape[0] < max_len:\n",
    "    \n",
    "                        difference = max_len - test_item.shape[0]\n",
    "    \n",
    "                        temp_np_inputs[0] = np.pad(test_item,((0,difference),(0,0)), mode=\"constant\")\n",
    "        \n",
    "           \n",
    "\n",
    "                \n",
    "            \n",
    "                feed = {inputs: temp_np_inputs,\n",
    "                        seq_len: batch_lengths}\n",
    "\t    \n",
    "\n",
    "            \n",
    "                \n",
    "               \n",
    "                \n",
    "                # Decoding\n",
    "                d = sess.run(decoded[0], feed_dict=feed)\n",
    "   \n",
    "                dense_decoded = tf.sparse_tensor_to_dense(d, default_value=-1).eval(session=sess)\n",
    "    \n",
    "                str_decoded = ''.join([keys_of_value(word_dictionary, x) for x in np.asarray(d[1]) ])\n",
    "    \n",
    "    \n",
    "                print(str_decoded)  \n",
    " \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_orange",
   "language": "python",
   "name": "tf_orange"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
